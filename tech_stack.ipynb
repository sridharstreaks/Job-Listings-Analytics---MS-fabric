{"cells":[{"cell_type":"code","source":["tech_stack = spark.sql(f\"SELECT tech_stack FROM bing_lake_db.naukri_jobs WHERE lower(job_title) LIKE '%{job_titles}%'\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"livy_statement_state":"available","session_id":"1ccbddf2-f2a3-4b0e-abb0-72939e03c7f7","state":"finished","normalized_state":"finished","queued_time":"2024-07-13T10:58:44.3451125Z","session_start_time":null,"execution_start_time":"2024-07-13T10:58:44.7327273Z","execution_finish_time":"2024-07-13T10:58:59.0930013Z","parent_msg_id":"18717f52-bb3e-4ff3-8505-f02f5c0f98db"},"text/plain":"StatementMeta(, 1ccbddf2-f2a3-4b0e-abb0-72939e03c7f7, 6, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bd0c1df6-500e-4225-8704-d9cb44046d44"},{"cell_type":"code","source":["display(tech_stack)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"livy_statement_state":"available","session_id":"1ccbddf2-f2a3-4b0e-abb0-72939e03c7f7","state":"finished","normalized_state":"finished","queued_time":"2024-07-13T10:59:00.7441812Z","session_start_time":null,"execution_start_time":"2024-07-13T10:59:01.1271103Z","execution_finish_time":"2024-07-13T10:59:05.9511107Z","parent_msg_id":"108804a7-faea-40ef-9e29-ab828ea82a10"},"text/plain":"StatementMeta(, 1ccbddf2-f2a3-4b0e-abb0-72939e03c7f7, 7, Finished, Available, Finished)"},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.synapse.widget-view+json":{"widget_id":"46beb0b7-bbda-4658-8d18-04d40501783e","widget_type":"Synapse.DataFrame"},"text/plain":"SynapseWidget(Synapse.DataFrame, 46beb0b7-bbda-4658-8d18-04d40501783e)"},"metadata":{}}],"execution_count":5,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"19085fc5-e5cb-48de-8006-52802ba5f018"},{"cell_type":"code","source":["from pyspark.sql.functions import split, explode\n","\n","# Split the string column by comma to create an array column\n","df_split = tech_stack.withColumn('tech_stack_array', split(tech_stack['tech_stack'], ','))\n","\n","# Explode the array column into rows\n","df_exploded = df_split.select(explode(df_split['tech_stack_array']).alias('tech_stack'))\n","\n","# Collect the values into a list\n","tech_stack = [row['tech_stack'] for row in df_exploded.collect()]\n","\n","tech_stack=[x.lower() for x in tech_stack]"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[8],"livy_statement_state":"available","session_id":"1ccbddf2-f2a3-4b0e-abb0-72939e03c7f7","state":"finished","normalized_state":"finished","queued_time":"2024-07-13T10:59:10.7404181Z","session_start_time":null,"execution_start_time":"2024-07-13T10:59:11.1101593Z","execution_finish_time":"2024-07-13T10:59:12.6192945Z","parent_msg_id":"56ac542a-4b3a-45d8-a829-c919d2bac08c"},"text/plain":"StatementMeta(, 1ccbddf2-f2a3-4b0e-abb0-72939e03c7f7, 8, Finished, Available, Finished)"},"metadata":{}}],"execution_count":6,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c18b8209-55f7-42a1-aa3f-406cf36c3973"},{"cell_type":"code","source":["import collections\n","from pyspark.sql.functions import col,lit\n","# Count occurrences\n","skill_counts = collections.Counter(tech_stack)\n","\n","# Convert Counter to DataFrame\n","tech_stack = spark.createDataFrame(list(skill_counts.items()), ['skill', 'count'])\n","\n","# Add a new column with a static value\n","tech_stack = tech_stack.withColumn('job_title', lit(f'{job_titles}'))\n","\n","# Optionally, you can sort the DataFrame by count descending\n","tech_stack = tech_stack.orderBy(col('count').desc())\n","\n","# Show the sorted DataFrame\n","tech_stack.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"livy_statement_state":"available","session_id":"1ccbddf2-f2a3-4b0e-abb0-72939e03c7f7","state":"finished","normalized_state":"finished","queued_time":"2024-07-13T10:59:18.5694308Z","session_start_time":null,"execution_start_time":"2024-07-13T10:59:18.9637202Z","execution_finish_time":"2024-07-13T10:59:20.455144Z","parent_msg_id":"5c42ac9f-5de7-44b4-8686-1689b60e7c22"},"text/plain":"StatementMeta(, 1ccbddf2-f2a3-4b0e-abb0-72939e03c7f7, 9, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+--------------------+-----+-------------+\n|               skill|count|    job_title|\n+--------------------+-----+-------------+\n|              python|   56|data engineer|\n|                 sql|   48|data engineer|\n|    data engineering|   47|data engineer|\n|             pyspark|   40|data engineer|\n|                data|   31|data engineer|\n|    data warehousing|   28|data engineer|\n|       data modeling|   22|data engineer|\n|     microsoft azure|   17|data engineer|\n|               scala|   17|data engineer|\n|                 etl|   16|data engineer|\n|               spark|   16|data engineer|\n|                 aws|   16|data engineer|\n|                 gcp|   15|data engineer|\n|  azure data factory|   15|data engineer|\n|            big data|   14|data engineer|\n|                hive|   14|data engineer|\n|information techn...|   13|data engineer|\n|               azure|   11|data engineer|\n|            aws glue|   11|data engineer|\n|       data engineer|   11|data engineer|\n+--------------------+-----+-------------+\nonly showing top 20 rows\n\n"]}],"execution_count":7,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6c7846e0-9972-4f8e-a18a-c9166df26656"},{"cell_type":"code","source":["from pyspark.sql.utils import AnalysisException\n","\n","try:\n","    table_name='bing_lake_db.tech_stack_count'\n","    tech_stack.write.format(\"delta\").saveAsTable(table_name)\n","except AnalysisException:\n","    print(\"Table Already Exists\")\n","    table_name='bing_lake_db.tech_stack_count'\n","    #tech_stack_existing = spark.sql(\"SELECT tech_stack FROM bing_lake_db.naukri_jobs\")\n","    tech_stack.createOrReplaceTempView(\"tech_stack_new\")\n","    spark.sql(f\"\"\"\n","                MERGE INTO {table_name} AS target\n","                USING (\n","                    SELECT job_title, skill, SUM(count) AS count\n","                    FROM (\n","                        SELECT job_title, skill, CAST(count AS BIGINT) AS count\n","                        FROM tech_stack_new\n","                        ORDER BY count DESC\n","                    )\n","                    GROUP BY job_title, skill\n","                ) AS source\n","                ON target.job_title = source.job_title AND target.skill = source.skill\n","                WHEN MATCHED THEN UPDATE SET target.count = target.count + source.count\n","                WHEN NOT MATCHED THEN INSERT (job_title, skill, count) VALUES (source.job_title, source.skill, source.count)       \n","                \"\"\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":21,"statement_ids":[21],"livy_statement_state":"available","session_id":"1ccbddf2-f2a3-4b0e-abb0-72939e03c7f7","state":"finished","normalized_state":"finished","queued_time":"2024-07-13T11:28:04.0275708Z","session_start_time":null,"execution_start_time":"2024-07-13T11:28:04.4308611Z","execution_finish_time":"2024-07-13T11:28:09.4505922Z","parent_msg_id":"2e95f864-6475-4610-b10f-7230ac5e333a"},"text/plain":"StatementMeta(, 1ccbddf2-f2a3-4b0e-abb0-72939e03c7f7, 21, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Table Already Exists\n"]}],"execution_count":19,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"191475b8-9fc1-4a85-aa88-4e698fc9e35a"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{"46beb0b7-bbda-4658-8d18-04d40501783e":{"type":"Synapse.DataFrame","sync_state":{"table":{"rows":[{"0":"GCP,Bigquery,Data Flow,Dataproc,Python,Airflow,Data Engineering,Flow","index":1},{"0":"SSMS,T-SQL,Data Engineering,SSIS,SQL,SSAS,Power Bi,ETL","index":2},{"0":"SSMS,T-SQL,Data Engineering,SSIS,SQL,SSAS,Power Bi,ETL","index":3},{"0":"Pyspark,Datafactory,AWS,Data Bricks,Data,Bricks,Data Engineering","index":4},{"0":"Pyspark,Datafactory,AWS,Data Bricks,Data,Bricks,Data Engineering","index":5},{"0":"Azure Data Factory,power automate,Power Apps Development,Powerapps,Application,Data Engineering,Factory,Data","index":6},{"0":"Azure Databricks,Azure Data Factory,Azure Data Lake,Azure Blob Storage,Data,Blob,Blob Storage,Microsoft Azure","index":7},{"0":"snowflake,Data Warehousing,Data Pipeline,Data Modeling,ETL,Python,sql,SR","index":8},{"0":"Snowflake,Data Warehousing,SQL,Data Pipeline,Data Modeling,ETL,Python,Warehouse","index":9},{"0":"Azure Data Engineer,Databricks,Python,Azure Data Factory,Azure Synapse,Pyspark,ADE,Azure Databricks","index":10},{"0":"Data Engineering,ETL,Python,SQL,Engineering,Data,Senior","index":11},{"0":"hive,access,scala,pyspark,data warehousing,data pipeline,sql,data cleansing","index":12},{"0":"Aws Lambda,aws redshift,Aws Glue,Python,SQL,Pyspark,Aws Cloud,Dynamo Db","index":13},{"0":"Azure Databricks,Azure Data Factory,Azure Data Lake,SQL Azure,Factory,Microsoft Azure,Data Lake,Data","index":14},{"0":"Pyspark,Spark,Python,Data Ingestion,Data Transformation,Data Engineering,Bigquery,Hadoop","index":15},{"0":"salesforce,data engineer,Data Engineering,Data Migration,Engineering,Migration,Data","index":16},{"0":"Hadoop,Redshift,MS SQL Server,AWS,Python,S3,EMR,Postgres SQL","index":17},{"0":"GCP,Spark,SQL,Data Engineering,Engineering,Data","index":18},{"0":"Pyspark,ADF,Databricks,Azure,Data,Microsoft Azure,Oracle ADF,Data Engineering","index":19},{"0":"Azure Data Factory,Azure Synapse,Pyspark,Python,Azure Databricks,Data,Microsoft Azure,Factory","index":20},{"0":"SQL,Data Engineering,data engineer,Python,Data,Engineering,Senior","index":21},{"0":"DynamoDB,EMR,Aws Glue,Lambda,Data,Data Engineering,Lambda Expressions,Dynamo Db","index":22},{"0":"Docker,Data Engineer,Python,Kubernetes,Data Engineering,Data","index":23},{"0":"Azure Data Factory,Azure Synapse,Pyspark,Azure Databricks,Python,Azure Data Lake,Data,Microsoft Azure","index":24},{"0":"s3,Amazon Redshift,Aws Glue,Athena,Aws Emr,java,SCALA,Hadoop","index":25},{"0":"Data Engineering,Dremio,Tableau,AWS,SQL,Data,Engineering","index":26},{"0":"Big Data,Hive,Hadoop,Spark,SQL,Python,Data","index":27},{"0":"Data Engineering,azure,API,Python,sql,Microsoft Azure,Data,Engineering","index":28},{"0":"Big Data,Data Science,Pyspark,Datafactory,Data Engineering,Data Pipeline,Data Scientist,Data Engineer","index":29},{"0":"Big Data,Data Science,Pyspark,Datafactory,Data Engineering,Data Pipeline,Data Scientist,Data Engineer","index":30},{"0":"Azure Data Factory,Pyspark,Azure Data Lake,ETL,Data Bricks,SQL,Python,Data","index":31},{"0":"Data Lake,Data Bricks,Python,Pyspark,AWS,SQL,Data,Bricks","index":32},{"0":"scala,glue,amazon redshift,delta,data warehousing,pyspark,dms,emr","index":33},{"0":"Big Data,Python,Hive,Spark,SQL,Data","index":34},{"0":"Java,Power Bi,ETL Tool,SQL,Python,Sql Programming,Data Engineering,data","index":35},{"0":"Etl Pipelines,Data Engineering,Spark,ETL,Python,Golang,Remote,Engineering","index":36},{"0":"Data Engineering,Pyspark,Matplotlib,Artificial Intelligence,Big Data,Data Visualization,DBMS,Data Modeling","index":37},{"0":"rdbms,sql queries,oracle,modeling,data warehousing,data pipeline,master data management,data engineering","index":38},{"0":"Usage,Infrastructure,Data quality,Customer experience,Continuous improvement,Data warehousing,Analytics,Recruitment","index":39},{"0":"Usage,SCALA,data governance,Data quality,Customer experience,Continuous improvement,Analytics,SQL","index":40},{"0":"Computer science,Engineering services,Bfsi,Healthcare,Data quality,Asset management,Information technology,Analytics","index":41},{"0":"data cleansing,SAP,Analytical,Data quality,FMCG,Information management,Informatica,Analytics","index":42},{"0":"SAN,Managed services,Coding,Agile,MongoDB,Gaming,SQL,Android","index":43},{"0":"Relationship management,Stakeholder Engagement,advanced analytics,Nutrition,Business analytics,MySQL,Wellness,data privacy","index":44},{"0":"Architect,Data analysis,orchestration,Business Analyst,Architectural design,Technical leadership,Data quality,data mapping","index":45},{"0":"Computer science,Business reporting,data engineer ii,Access management,Manager Technology,Data structures,Data quality,Business solutions","index":46},{"0":"Computer science,Change management,ISO,Active directory,Problem management,DNS,Windows,microsoft","index":47},{"0":"Automation,Version control,GIT,Data modeling,Healthcare,Data processing,Wellness,Data quality","index":48},{"0":"Supply chain,Service management,Automation,Coding,Data processing,Data mining,Operations,Analytics","index":49},{"0":"AWS,Data,Senior","index":50},{"0":"SUB,NoSQL,GCP,spark,SCALA,MongoDB,big data,SQL","index":51},{"0":"Usage,Data management,big data,Data entry,Data Engineering,Management,Data","index":52},{"0":"Computer science,System architecture,Coding,Data modeling,Data processing,Business strategy,Informatica,SSIS","index":53},{"0":"Computer science,System architecture,Coding,Data modeling,Data processing,Business strategy,Informatica,SSIS","index":54},{"0":"metadata,GCP,Postgresql,SCALA,Data processing,Scrum,Data quality,Information technology","index":55},{"0":"Automation,Data modeling,Analytical,Data structures,Data quality,Analytics,Monitoring,SQL","index":56},{"0":"Cloud computing,Data management,Coding,Database design,data security,Data modeling,Agile,Data processing","index":57},{"0":"Linux,data security,Windows,microsoft,Data mining,Information technology,Pentaho,SQL","index":58},{"0":"Pyspark,R,AWS,Nodejs,Python,NLP,MLOps,Data Engineering","index":59},{"0":"Data Engineering,AWS,Pyspark,CI/CD,Spark,ITIL,Python,DBMS","index":60},{"0":"Data Engineering,Airflow,Java,Scala,Kafka,Big Data,AWS Glue,data architecture","index":61},{"0":"informatica powercenter,information management,data warehousing,business intelligence,splunk,python,power bi,relational sql","index":62},{"0":"GCP,BigQuery,NoSQL,Snowflake,relational databases,Redshift,Python,SQL","index":63},{"0":"AWS Glue,cloud,technical support,data analysis,data modeling,Kafka Connect,data collection,Flink","index":64},{"0":"data warehousing,warehouse,data engineering,agile,etl,hive,python,sql development","index":65},{"0":"informatica powercenter,information management,business intelligence,elastic search,etl,python,data warehousing,power bi","index":66},{"0":"AWS,S3,Power BI,Data formation,data warehousing,AWS CodeBuilt,Tableau,ITIL","index":67},{"0":"data engineering,C#,Hive,Apache Flink,Snowflake,Kafka,Apache Cassandra,DynamoDB","index":68},{"0":"sharepoint,sql,jira,snowflake,unix,hive,data warehousing,spark","index":69},{"0":"SCALA,Delta lake,Kafka,Spark,Java,Hive,C++,PowerBI","index":70},{"0":"AWS,Apache Airflow,Data Pipeline,PySpark,Spark,Data Modeling,Data Warehousing,ETL","index":71},{"0":"Azure Data Factory,Data Engineering,Azure Synapse Analytics,Azure Data Lake,ETL,Azure SQL,SQL,Python","index":72},{"0":"Data Engineering,Reporting Analytics,Power BI,Scala,Cloud,Data Engineer,Dashboard Design,Snowflake DB","index":73},{"0":"google,data architecture,machine learning,data modeling,data science,hive,python,data security","index":74},{"0":"Data Engineering,Airflow,Java,Azure,Scala,SQL,Hive,Sqoop","index":75},{"0":"google,data architecture,machine learning,data modeling,data science,hive,python,data security","index":76},{"0":"ETL,Airflow,Step Function,Power BI,PySpark,AWS CloudTrail,AWS Glue,Tableau","index":77},{"0":"sharepoint,sql,jira,snowflake,unix,hive,data warehousing,spark","index":78},{"0":"python,pyspark,sql,data bricks,gcp,hive,data analytics,scala","index":79},{"0":"Python,Pyspark,Github,SVN,AL,Nodejs,SQL,R","index":80},{"0":"Azure Data Factory,Azure Databricks,SQL,Pyspark,Factory,Microsoft Azure,Data","index":81},{"0":"data modeling,Data Visualization,Tableau,alteryx,SQL,Data Analytics,Python,Analytics","index":82},{"0":"Pyspark,Hadoop,SCALA,Spark,SQL,Big Data,Data Bricks,Data Engineering","index":83},{"0":"Pyspark,apache spark,Data Engineer,SQL,Python,Azure Cloud,Postgresql,Cloud","index":84},{"0":"python,pyspark,numpy,aws,sql,Data,Data Engineering,Artificial Intelligence","index":85},{"0":"NSQL,Airflow,Pyspark,Data Warehouse Testing,DBMS,Proofhub,AWS,SQL","index":86},{"0":"Data Engineering,Shell scripting,SNowflake,Python,Data,Scripting,Engineering","index":87},{"0":"Informatica.,Data Engineering,Snowflake,Idq,Python,Denodo,Data Management Program,Chief Data Office","index":88},{"0":"Team Management,PySpark,Client Interaction,AWS/Azure/GCP,SQL,Big Data,Data Warehousing,Data Architecture","index":89},{"0":"python,software development,software testing,unit testing,testing methodologies,business analysis,numpy,machine learning","index":90},{"0":"information technology,data warehousing,data engineering,database creation,big data,hive,python,oracle","index":91},{"0":"information technology,data warehousing,qlikview,data modeling,data integration,talend,microsoft azure,data engineering","index":92},{"0":"information technology,scala,pyspark,data warehousing,distributed computing,python,talend,microsoft azure","index":93},{"0":"information technology,scala,data warehousing,distributed computing,sql,python,talend,pyspark","index":94},{"0":"information technology,qlikview,data modeling,data warehousing concepts,design principles,talend,microsoft azure,data warehousing","index":95},{"0":"python,Azure,java,spark,GCP,Real time database,Big data,DBMS","index":96},{"0":"AWS Glue,Redshift,SQL,Data Model development,SQL programming,stream processing,BI,Data Engineer","index":97},{"0":"Kafka Connect,GCP,Kafka,Data Engineering,Contracts,Kafka Streams,Connect,Data","index":98},{"0":"Data Engineering,Software development,GitHub,data warehousing,Data Modeling,build management,ETL,SSIS","index":99},{"0":"Data Engineer,Azure,Data Pipeline,Cloud,Data Architecture,Tableau,Python,SQL","index":100},{"0":"GCP,Pubsub,Bigquery,Data Flow,Dataproc,Flow,Data,Senior","index":101},{"0":"Data Engineering,aws glue,cloud,technical support,data analysis,data modeling,Kafka Connect,data collection","index":102},{"0":"Hadoop,Spark,AWS,SQL,Python,Pyspark,Java,GCP","index":103},{"0":"Snowflake,Ab Initio,ETL,AWS,Data warehousing,SQL,Ab,Senior","index":104},{"0":"Azure,Pyspark,Azure cloud services,Python,Azure Data Factory,Azure Cloud,Cloud,Microsoft Azure","index":105},{"0":"Pyspark,python,Shell Scripting,azure,SQL,Azure Data Factory,Data Engineering,Azure Databricks","index":106},{"0":"python,software development,software testing,unit testing,testing methodologies,business analysis,numpy,machine learning","index":107},{"0":"information technology,data warehousing,data engineering,database creation,big data,hive,python,oracle","index":108},{"0":"information technology,data warehousing,qlikview,data modeling,data integration,talend,microsoft azure,data engineering","index":109},{"0":"information technology,scala,pyspark,data warehousing,distributed computing,python,talend,microsoft azure","index":110},{"0":"information technology,scala,data warehousing,distributed computing,sql,python,talend,pyspark","index":111},{"0":"information technology,qlikview,data modeling,data warehousing concepts,design principles,talend,microsoft azure,data warehousing","index":112},{"0":"python,Azure,java,spark,GCP,Real time database,Big data,DBMS","index":113},{"0":"AWS Glue,Redshift,SQL,Data Model development,SQL programming,stream processing,BI,Data Engineer","index":114},{"0":"Kafka Connect,GCP,Kafka,Data Engineering,Contracts,Kafka Streams,Connect,Data","index":115},{"0":"Data Engineering,Software development,GitHub,data warehousing,Data Modeling,build management,ETL,SSIS","index":116},{"0":"Data Engineer,Azure,Data Pipeline,Cloud,Data Architecture,Tableau,Python,SQL","index":117},{"0":"GCP,Pubsub,Bigquery,Data Flow,Dataproc,Flow,Data,Senior","index":118},{"0":"Data Engineering,aws glue,cloud,technical support,data analysis,data modeling,Kafka Connect,data collection","index":119},{"0":"Hadoop,Spark,AWS,SQL,Python,Pyspark,Java,GCP","index":120},{"0":"Snowflake,Ab Initio,ETL,AWS,Data warehousing,SQL,Ab,Senior","index":121},{"0":"Azure,Pyspark,Azure cloud services,Python,Azure Data Factory,Azure Cloud,Cloud,Microsoft Azure","index":122},{"0":"Pyspark,python,Shell Scripting,azure,SQL,Azure Data Factory,Data Engineering,Azure Databricks","index":123},{"0":"python,Microsoft SQL Server Integration Services,azure data lake,scala,Informatica PowerCenter,power bi,pyspark,AWS Glue","index":124},{"0":"AWS Services,S3,python,postgresql,hybrid cloud,AWS CodePipeline,aws cloudformation,Lambda","index":125},{"0":"Airflow,BigQuery,GCP,Python,SQL,Dataproc,Google Cloud Platforms,Dataflow","index":126},{"0":"Computer science,Manager Quality Assurance,Data modeling,Analytical,Data processing,Data quality,Continuous improvement,Operations","index":127},{"0":"Azure Data Factory,Pyspark,Azure Data Lake,Azure Databricks,Data,Microsoft Azure,Data Lake,Factory","index":128},{"0":"Microsoft Technologies,c#,Pyspark,Power Bi,Microsoft Azure,Azure Data Factory,Azure Data Lake,Azure Databricks","index":129}],"schema":[{"key":"0","name":"tech_stack","type":"string"}],"truncated":false},"isSummary":false,"language":"scala"},"persist_state":{"view":{"type":"details","tableOptions":{},"chartOptions":{"chartType":"bar","categoryFieldKeys":["0"],"seriesFieldKeys":["0"],"aggregationType":"count","isStacked":false,"binsNumber":10,"wordFrequency":"-1"}}}}}},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"4d925880-0687-476a-8889-63574bd1cf40","default_lakehouse_name":"bing_lake_db","default_lakehouse_workspace_id":"9a7e0483-f099-4633-84bd-1059c3683d26"}}},"nbformat":4,"nbformat_minor":5}